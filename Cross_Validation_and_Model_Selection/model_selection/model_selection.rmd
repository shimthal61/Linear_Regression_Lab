---
title: "Model Selection"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_float: yes
    font:family: Lato
  pdf_document:
    toc: yes
---

# Regression Models

When presented when a regression problem and a data set of potential input variables, it can be difficult to know where to start. There are a couple of approaches we can use here. Either we just include *everything* in our model at the beginning, and then try to refine in later, or we try and build the model up more slowly by choosing a subset of input variables that appear most relevant, adding mroe later if we want to further improve the model. If the number of input variables is reasonably small, then including everything at once can be fine, otherwise I can start with correlation plots of the relationships in the data to determine by eye which appear most relevant. The `corrplot` package can help visualise the magnitude of correlations.

```{r}
library(ISLR2)
library(corrplot)

cor <- cor(Boston)
corrplot(cor)
```

## Linear Fit

Now that we have an initial set of variables, the easiest thing to do is fit a basic linear regression model using all the input variables. We can then calculate the MSE for this model that will give a baseline value that we can attempt to later minimise. The next step would be to check the regression assumptions. Importantly, what we care about here would be the VIF (as variables too highly correlated will cause issues irrespective of the model we use), and any evidence of non-linearity. Any of the assumption plots that depend upon the model fit (such as outliers, leverage points, normality, and homogeneuity of variance) can be ignored for now because we have not settled on our final model fit.

The plan at this stage is to work on each input variable in turn to see if using a *non-linear* aproach will improve things. This can start with identifying non-linearity in the assumption plots, but one of the best ways is to view the fitted effect with the *partial residuals*. For instance, in the "Auto" dataset, if we were working with the model `lm(mpg ~ weight + horsepower, data = Auto)`, we would start by focusing on the `weight` variable.

```{r}
library(performance)
library(see)
model <- lm(mpg ~ weight + horsepower, data = Auto)
check_model(model)
```

```{r}
library(effects)
plot(effect("weight", mod = model, partial.residuals = TRUE))
```

The plot above shows the model prediction and 95% confidence bands in blue, as well as the partial residuals as pink circles. The general shape in the data is given by the pink lines (using LOESS smoothing method). The degree to which the blue model fit differes from the pink suggests that we may not be capturing the correct shape of the relationship.

## Polynomial Fit

In this example, there seems to be a non-linear relationship between `weight` and `mpg`. We may decide to first try a polynomial fit and use cross-validation to determine the degree of the polynomial. We can try up to an 8th degree polynomial, where we repeatedly use the `train()` function with a different model formula, then gather the MSE values and store them in a vector for plotting

```{r}
library(caret)

data("Auto")

set.seed(42)

train_control <- trainControl(method = "LOOCV")

fit_1 <- train(mpg ~ weight + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_2 <- train(mpg ~ poly(weight, 2) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_3 <- train(mpg ~ poly(weight, 3) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_4 <- train(mpg ~ poly(weight, 4) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_5 <- train(mpg ~ poly(weight, 5) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_6 <- train(mpg ~ poly(weight, 6) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_7 <- train(mpg ~ poly(weight, 7) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

fit_8 <- train(mpg ~ poly(weight, 8) + horsepower,
  data = Auto, method = "lm", trControl = train_control)

mse <- rep(0, 8)

mse[1] <- fit_1$results$RMSE
mse[2] <- fit_2$results$RMSE
mse[3] <- fit_3$results$RMSE
mse[4] <- fit_4$results$RMSE
mse[5] <- fit_5$results$RMSE
mse[6] <- fit_6$results$RMSE
mse[7] <- fit_7$results$RMSE
mse[8] <- fit_8$results$RMSE

plot(1:8, mse, type = "b", xlab = "degree")
```

This produces this plot, which shows us that the smallest RMSE is associated with the 4th-degree polynomial. Let's replot the partial residuals with our polynomial model


## Basis Splines

We might also want to consider an alternative approach, such as using basis splines. The `train()' function is not very smart, and cannot be ran inside of a loop. As such, we make a copy of the data and then append the result of `poly` or `bs` as a new variable, which we then refer to inside the model. This is shown below for 20 possible values for the degrees of freedom. 

```{r}
library(splines)

mse <- rep(0, 20)

for (i in 1:20) {
  Data <- Auto
  Data$bspline <- bs(Auto$weight, df=i)
  fit <- train(mpg ~ bspline + horsepower, data = Data, method = "lm", trControl = train_control)
  mse[i] <- fit$results$RMSE
}

plot(1:20, mse, type = "b", xlab = "df")

mse[8] > mse[9]
```

We can see here that 9 degrees of freedom produces the lowest MSE.

```{r}
bs_fit <- train(mpg ~ bs(weight, df = 9), data = Auto, method = "lm", trControl = train_control)
```

We could do the same sort of cross-validation exercise with natural and smoothing splines, and then compare the fits visually (using `plot.gam(mod.1, residuals=T` for a GAM model), and try to decide which is the best fit from the information we have available. 

## Natural Splines

```{r}
mse <- rep(0, 20)

for (i in 1:20) {
  Data <- Auto
  Data$nspline <- ns(Auto$weight, df=i)
  fit <- train(mpg ~ nspline + horsepower, data = Data, method = "lm", trControl = train_control)
  mse[i] <- fit$results$RMSE
}

which.min(mse)

plot(1:20, mse, type = "b", xlab = "df")
```

# Example

```{r}
# 0 Inputs
mod_0 <- lm(mpg ~ 1, data = Auto)

# 1 Input
weight_fit <- lm(mpg ~ poly(weight, 4), data = Auto)
horse_fit <- lm(mpg ~ poly(horsepower, 2), data = Auto)
cylind_fit <- lm(mpg ~ cylinders, data = Auto)
which.min(c(deviance(weight_fit), deviance(horse_fit), deviance(cylind_fit)))

# poly(weight, 4) is the winner

# 2 Inputs

weight_horse_fit <- lm(mpg ~ poly(weight, 4) + poly(horsepower, 2), data = Auto)
weight_cyl_fit <- lm(mpg ~ poly(weight, 4) + cylinders, data = Auto)
horse_cyl_fit <- lm(mpg ~ poly(horsepower, 2) + cylinders, data = Auto)
which.min(c(deviance(weight_horse_fit), deviance(weight_cyl_fit), deviance(horse_cyl_fit)))

# poly(weight, 4) + poly(horsepower, 2) is the winner

# 3 Inputs

full_fit <- lm(mpg ~ poly(weight, 4) + poly(horsepower, 2) + cylinders, data = Auto)

# Cross Validation
Auto$const <- rep(0, dim(Auto)[1])

fit_1 <- train(mpg ~ const, data = Auto, method = "lm", trControl = train_control)
fit_2 <- train(mpg ~ poly(weight, 4), data = Auto, method = "lm", trControl = train_control)
fit_3 <- train(mpg ~ poly(weight, 4) + poly(horsepower, 2), data = Auto, method = "lm", trControl = train_control)
fit_4 <- train(mpg ~ poly(weight, 4) + poly(horsepower, 2) + cylinders, data = Auto, method = "lm", trControl = train_control)

mod_comp <- data.frame(mse = c(fit_1$results$RMSE, fit_2$results$RMSE, fit_3$results$RMSE, fit_4$results$RMSE),
                      Inputs = c(0, 1, 2, 3))

plot(mod_comp$Inputs, mod_comp$mse, type = "b", xlab = "Number of Input Variables", ylab = "RMSE")
```

The conclusion is that two inputs of horsepower and weight make the model better than each term individually, but adding a third input (the cylinders variable) makes no appreciable improvement. In this instance we would likely drop cylinders from the model and stick with only two inputs as our final predictive model.

# Classification Models

Again, we'll start somewhere simple - logistic regression for classification. We can then follow the same process of plotting and trying different non-linear transformations if the model needs them. When plotting logistic regression models, you can specify an argument of either `type = "link"` or `type = "response"` in the `plot()` command, from the `effect()` package. This will show either the model fit on the *logic* scale or or the *binary* scale of the data. The *logit* scale is where we assume the response is linear and so `type = "link"` should be used when looking for the possibility of *non-linear* relationships. 

For example, the code below (for an arbitrary splitting of the mpg variable from the Auto data set)

```{r}
Auto$mpg_bin <- as.factor(Auto$mpg > 23)

fit <- glm(mpg_bin ~ weight + horsepower, data = Auto, family = "binomial")

par(mfrow = c(2, 2))
plot(effect("weight", mod = fit, partial.residuals = TRUE, type = "reponse"))
plot(effect("weight", mod = fit, partial.residuals = TRUE, type = "link"))
```